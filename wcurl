#!/bin/bash

# wcurl - a simple wrapper around curl to easily download files.

set -e

usage() {
    cat << _EOF_
$0 -- a simple wrapper around curl to easily download files.

Usage: $0 [-o <CURL_OPTIONS>|--opts=<CURL_OPTIONS>] <URL>...

Options:

  -o,--opts <CURL_OPTIONS>: Specify extra options to be
                            passed when invoking curl.

  <URL>: The URL to be downloaded.  May be specified more than once.
_EOF_
}

error() {
    printf "%s\n" "$*" > /dev/stderr
    exit 1
}

OPTS=$(getopt --options "o:h" --longoptions "opts:,help" --name wcurl -- "$@")

eval set -- "${OPTS}"

# Extra curl options.
# FIXME: Should this really be per-URL?
CURL_OPTIONS=""

# The URLs to be downloaded.
URLS=""

# Set this to "--parallel" if there's more than one URL to download.
CURL_PARALLEL=""

# Parameters to be passed for each URL.
PER_URL_PARAMETERS="--location --remote-name --remote-time --retry 10 --retry-max-time 10 --continue-at - "

# Sanitize parameters.
sanitize()
{
    if [ -z "${URLS}" ]; then
	error "You must provide at least one URL to download."
    fi

    if [ -n "${CURL_OPTIONS}" ]; then
	PER_URL_PARAMETERS="${PER_URL_PARAMETERS} ${CURL_OPTIONS} "
    fi

    readonly CURL_OPTIONS URLS PER_URL_PARAMETERS CURL_PARALLEL
}

# Execute curl with the list of URLs provided by the user.
exec_curl()
{
    set -- $URLS

    # We can't use --next for the first URL.
    CMD="curl ${CURL_PARALLEL} ${PER_URL_PARAMETERS} ${1} "

    shift
    for url in "$@"; do
	CMD="${CMD} --next ${PER_URL_PARAMETERS} ${url}"
    done

    echo exec $CMD
}

while [ -n "${1}" ]; do
    case "${1}" in
	"-o"|"--opts")
	    shift
	    CURL_OPTIONS="${CURL_OPTIONS} ${1}"
	    ;;

	"-h"|"--help")
	    usage
	    exit 0
	    ;;

	"--")
	    # This is the start of the list of URLs.
	    shift
	    if [ "$#" -gt 1 ]; then
		CURL_PARALLEL="--parallel"
	    fi
	    for url in "$@"; do
		newurl=$(printf "%s\n" "${url}" | sed 's/ /%20/g')
		URLS="${URLS} ${newurl}"
	    done
	    break
	    ;;
    esac
    shift
done

sanitize
exec_curl
